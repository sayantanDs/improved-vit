{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"YzmQsQNryKnl"},"source":["# **Imports**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"XYJqOjaEyMFX"},"outputs":[],"source":["import os\n","import shutil\n","import json\n","from contextlib import redirect_stdout\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1681302237966,"user":{"displayName":"Sayantan Das","userId":"12952302728003162897"},"user_tz":-330},"id":"7X3h_QxH49wh","outputId":"19b18687-d68f-4888-ef6d-cae6ce6bdd93"},"outputs":[],"source":["gpu_devices = tf.config.list_physical_devices('GPU')\n","print(gpu_devices)\n","tf.config.experimental.set_memory_growth(gpu_devices[0], True)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"mn1If3xdvHUs"},"source":["# **Dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"knTdC1d6vI4s"},"outputs":[],"source":["dataset_path = \"../speech_commands_v2_spectrograms/\"\n","output_path = \"./save_files/\"\n","save_folder = \"cvit\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"tkddphfPvLK8"},"outputs":[],"source":["train_dir = os.path.join(dataset_path, \"train\")\n","test_dir = os.path.join(dataset_path, \"test\")\n","val_dir = os.path.join(dataset_path, \"val\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"FUdcWM5bvOb5"},"outputs":[],"source":["label_names = np.array([x for x in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir,x))])\n","label_names.sort()\n","num_labels = len(label_names)\n","\n","print(num_labels, \"labels:\\n\", label_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_qvahk2BvQuh"},"outputs":[],"source":["IMG_SIZE = (128, 101)\n","BATCH_SIZE = 32\n","\n","input_shape = IMG_SIZE + (1,)\n","\n","train_ds = tf.keras.utils.image_dataset_from_directory(\n","    train_dir,\n","    shuffle=True,\n","    color_mode=\"grayscale\",\n","    batch_size=BATCH_SIZE,\n","    image_size=IMG_SIZE\n",")\n","\n","val_ds = tf.keras.utils.image_dataset_from_directory(\n","    val_dir,\n","    shuffle=True,\n","    color_mode=\"grayscale\",\n","    batch_size=BATCH_SIZE,\n","    image_size=IMG_SIZE\n",")\n","\n","test_ds = tf.keras.utils.image_dataset_from_directory(\n","    test_dir,\n","    shuffle=False,\n","    color_mode=\"grayscale\",\n","    batch_size=BATCH_SIZE,\n","    image_size=IMG_SIZE\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L__KSyTBvWUy"},"outputs":[],"source":["rescale = tf.keras.layers.Rescaling(scale=1./255)\n","def rescale_ds(x, y):\n","    return rescale(x), y\n","\n","train_ds = train_ds.map(rescale_ds)\n","test_ds = test_ds.map(rescale_ds)\n","val_ds = val_ds.map(rescale_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z-ISftY3vZQz"},"outputs":[],"source":["train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n","val_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n","# test_ds = test_ds.prefetch(tf.data.AUTOTUNE)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"cOoQISfzvmHt"},"source":["# **Save Helpers**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MfHCWtRvvo8e"},"outputs":[],"source":["model_save_loc =  os.path.join(output_path, save_folder)\n","print(\"Model save location:\", model_save_loc)\n","os.makedirs(model_save_loc, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qLjYpoHyv7T4"},"outputs":[],"source":["def get_prev_save_file_name(model_save_loc):\n","    prev_save_file=\"\"\n","\n","    save_files = os.listdir(model_save_loc)\n","    save_files = [k for k in save_files if (k[-2:]==\"h5\" and k[-7:-3]!=\"best\")]\n","    if len(save_files)>=1:    \n","        save_files.sort(reverse=True)\n","        prev_save_file = save_files[0]\n","\n","    return prev_save_file\n","\n","\n","def get_prev_best_save_file_name(model_save_loc):\n","    prev_best_file = \"\"\n","\n","    save_files = os.listdir(model_save_loc)\n","    best_save_files = [k for k in save_files if k[-7:]==\"best.h5\"]\n","    if len(best_save_files)>=1:    \n","        best_save_files.sort(reverse=True)\n","        prev_best_file = best_save_files[0]\n","    \n","    return prev_best_file\n","\n","\n","\n","class CustomModelCheckPoint(tf.keras.callbacks.Callback):\n","    def __init__(self, model_save_loc, prev_save_file=\"\", prev_best_file=\"\", prev_best_acc=0, model_name=\"epoch\", **kargs):\n","        super(CustomModelCheckPoint,self).__init__(**kargs)\n","        self.model_save_loc = model_save_loc\n","        self.model_name = model_name\n","        self.prev_save_file = prev_save_file\n","        self.prev_best_file = prev_best_file\n","        self.prev_best_acc = prev_best_acc\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        # acc = logs.get(\"accuracy\")\n","        val_acc = logs.get(\"val_accuracy\")\n","\n","        filename =  f\"{self.model_name}_{(epoch+1):03d}-{val_acc:.3f}.h5\"\n","        self.model.save_weights(os.path.join(self.model_save_loc, filename)) # save the model\n","        \n","        # remove previous epoch save files\n","        if self.prev_save_file:\n","            delete_filename = os.path.join(self.model_save_loc, self.prev_save_file)\n","            open(delete_filename, 'w').close() # overwrite and make the file blank\n","            os.remove(delete_filename)\n","        self.prev_save_file = filename\n","\n","        # save best model till now\n","        if val_acc > self.prev_best_acc:           \n","            best_filename = filename[:-3]+\"_best.h5\"\n","            shutil.copy(os.path.join(self.model_save_loc, filename), os.path.join(self.model_save_loc, best_filename))\n","           \n","            if self.prev_best_file:\n","                delete_filename = os.path.join(self.model_save_loc, self.prev_best_file)\n","                open(delete_filename, 'w').close() # overwrite and make the file blank\n","                os.remove(delete_filename)\n","           \n","            self.prev_best_acc = val_acc\n","            self.prev_best_file = best_filename"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ZWVuzUiOufKm"},"source":["# **Model**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"XnJ8aNOtutnJ"},"source":["## **Layers**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F0ZE5qEKuvN3"},"outputs":[],"source":["def generate_patches(inputs, patch_size, patch_overlap=0, hidden_size=None):\n","    patch_stride = patch_size - patch_overlap\n","    if hidden_size is None:\n","        hidden_size = patch_stride * patch_stride\n","\n","    patches = tf.keras.layers.Conv2D(\n","        filters=hidden_size, \n","        kernel_size=patch_size, \n","        strides=patch_stride, \n","        padding='valid',\n","        name='embedding'\n","    )(inputs)\n","    \n","    _, w, h, _ = patches.shape\n","\n","    # seq_len = (inputs.shape[1] // patch_size) * (inputs.shape[2] // patch_size)\n","    seq_len = w*h\n","    x = tf.reshape(patches, [-1, seq_len, hidden_size])\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PjphbC8yuw3Q"},"outputs":[],"source":["# taken from https://github.com/tensorflow/models/blob/master/official/vision/modeling/backbones/vit.py\n","@tf.keras.utils.register_keras_serializable()\n","class TokenLayer(tf.keras.layers.Layer):\n","    \"\"\"A simple layer to wrap token parameters.\"\"\"\n","\n","    def build(self, inputs_shape):\n","        self.cls = self.add_weight(\n","            'cls', (1, 1, inputs_shape[-1]), initializer='zeros')\n","\n","    def call(self, inputs):\n","        cls = tf.cast(self.cls, inputs.dtype)\n","        cls = cls + tf.zeros_like(inputs[:, 0:1])  # A hacky way to tile.\n","        x = tf.concat([cls, inputs], axis=1)\n","        return x\n","    \n","    def get_config(self):\n","        config = super().get_config()\n","        return config\n","\n","    @classmethod\n","    def from_config(cls, config):\n","        return cls(**config)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YbXJQnhnuy8J"},"outputs":[],"source":["@tf.keras.utils.register_keras_serializable()\n","class AddPositionEmbs(tf.keras.layers.Layer):\n","    \"\"\"Adds (optionally learned) positional embeddings to the inputs.\"\"\"\n","\n","    def build(self, inputs_shape):\n","        pos_emb_shape = (1, inputs_shape[1], inputs_shape[2])\n","        self.pos_embedding = self.add_weight(\n","            'pos_embedding', \n","            pos_emb_shape, \n","            initializer=tf.keras.initializers.RandomNormal(stddev=0.02)\n","        )\n","\n","    def call(self, inputs, inputs_positions=None):\n","        # inputs.shape is (batch_size, seq_len, emb_dim).\n","        pos_embedding = tf.cast(self.pos_embedding, inputs.dtype)\n","\n","        return inputs + pos_embedding\n","    \n","    def get_config(self):\n","        config = super().get_config()\n","        return config\n","\n","    @classmethod\n","    def from_config(cls, config):\n","        return cls(**config)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jDTpbi7iu1dx"},"outputs":[],"source":["def mlp_block(inputs, mlp_dim, dropout_rate, activation=tf.nn.gelu):\n","    x = tf.keras.layers.Dense(units=mlp_dim, activation=activation)(inputs)\n","    if dropout_rate>0:\n","        x = tf.keras.layers.Dropout(rate=dropout_rate)(x)\n","    x = tf.keras.layers.Dense(units=inputs.shape[-1], activation=activation)(x)\n","    if dropout_rate>0:\n","        x = tf.keras.layers.Dropout(rate=dropout_rate)(x)\n","\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0nFmdSjFu3DI"},"outputs":[],"source":["def ConvolutionModule(inputs, conv_dropout_rate, activation='relu'):\n","    x = tf.keras.layers.LayerNormalization(dtype=inputs.dtype)(inputs)\n","\n","    _, _, hidden_size = inputs.shape\n","    x = tf.keras.layers.Conv1D(hidden_size*2 , 3, padding=\"same\", activation=activation)(x)\n","    x = tf.keras.layers.BatchNormalization()(x)\n","    \n","    x = tf.keras.layers.Conv1D(hidden_size, 3, padding=\"same\", activation=activation)(x)\n","    x = tf.keras.layers.BatchNormalization()(x)\n","\n","    if conv_dropout_rate>0:\n","        x = tf.keras.layers.Dropout(rate=conv_dropout_rate)(x)\n","    \n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gJXILPnUu4sB"},"outputs":[],"source":["def Conv_TransformerEncoder1Dblock(inputs, num_heads, mlp_dim, dropout_rate, attention_dropout_rate, conv_dropout_rate, mlp_activation=tf.nn.gelu, conv_activation='relu'):\n","    # MHSA\n","    x = tf.keras.layers.LayerNormalization(dtype=inputs.dtype)(inputs)\n","    x = tf.keras.layers.MultiHeadAttention(\n","        num_heads=num_heads, \n","        key_dim=inputs.shape[-1], \n","        dropout=attention_dropout_rate\n","    )(x, x) # self attention multi-head\n","    x = tf.keras.layers.Add()([x, inputs]) # 1st residual part \n","    \n","    # convolution module\n","    x1 = ConvolutionModule(x, conv_dropout_rate, conv_activation)\n","    x1 = tf.keras.layers.Add()([x1, x]) # 2nd residual part \n","    \n","\n","    y = tf.keras.layers.LayerNormalization(dtype=x1.dtype)(x1)\n","    y = mlp_block(y, mlp_dim, dropout_rate, mlp_activation)\n","    y_1 = tf.keras.layers.Add()([y, x1]) # 3rd residual part \n","    \n","    return y_1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u7_RtXadujYO"},"outputs":[],"source":["def Conv_TransformerEncoder(inputs, num_layers, mlp_dim, num_heads, dropout_rate, attention_dropout_rate, conv_dropout_rate, mlp_activation=tf.nn.gelu, conv_activation='relu'):\n","    x = AddPositionEmbs(name='posembed_input')(inputs)\n","    \n","    if dropout_rate>0:\n","        x = tf.keras.layers.Dropout(rate=dropout_rate)(x)\n","\n","    for _ in range(num_layers):\n","        x = Conv_TransformerEncoder1Dblock(x, num_heads, mlp_dim, dropout_rate, attention_dropout_rate, conv_dropout_rate, mlp_activation, conv_activation)\n","\n","    encoded = tf.keras.layers.LayerNormalization(name='encoder_norm')(x)\n","    return encoded"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"KNZ3zvNcu9XT"},"source":["## **Create Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WRoYf8zRugYu"},"outputs":[],"source":["def conv_vision_transformer(\n","        input_shape,\n","        classes,\n","        patch_size=16, \n","        patch_overlap=8, \n","        hidden_size=64, \n","        num_transformer_layers=12,\n","        num_heads=12,\n","        mlp_dim=256,\n","        dropout_rate=0.5, \n","        attention_dropout_rate=0.2,\n","        conv_dropout_rate=0.2,\n","        mlp_activation=tf.nn.gelu,\n","        conv_activation='swish'\n","    ):\n","\n","    inputs = tf.keras.layers.Input(shape=input_shape)\n","    x = inputs\n","\n","    x = tf.keras.layers.Conv2D(\n","        filters=8, \n","        kernel_size=(3, 3), \n","        strides=(1, 1), \n","        padding='same',\n","        activation=\"relu\",\n","        name=\"conv_features_1\"\n","    )(x)\n","    x = tf.keras.layers.BatchNormalization(name=f\"conv_features_1_batchnorm\")(x)\n","\n","    x = tf.keras.layers.Conv2D(\n","        filters=8, \n","        kernel_size=(3, 3), \n","        strides=(1, 1), \n","        padding='same',\n","        activation=\"relu\",\n","        name=\"conv_features_2\"\n","    )(x)\n","    x = tf.keras.layers.BatchNormalization(name=f\"conv_features_2_batchnorm\")(x)\n","    \n","\n","    # Create patches.\n","    x = generate_patches(\n","        x,\n","        patch_size, \n","        patch_overlap,\n","        hidden_size\n","    )\n","\n","    # Add CLS token\n","    x = TokenLayer(name='cls')(x)\n","\n","    # Transformer encoder blocks\n","    x = Conv_TransformerEncoder(\n","        x,\n","        num_transformer_layers, \n","        mlp_dim, \n","        num_heads, \n","        dropout_rate, \n","        attention_dropout_rate,\n","        conv_dropout_rate,\n","        mlp_activation,\n","        conv_activation\n","    )\n","\n","    # take only the CLS token output\n","    x = x[:, 0]\n","\n","    predictions = tf.keras.layers.Dense(classes, name='predictions', activation='softmax')(x)\n","\n","    # final model\n","    model = tf.keras.Model(inputs=inputs, outputs=predictions)   \n","    \n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XXxSe26rwJ3B"},"outputs":[],"source":["model = conv_vision_transformer(\n","    input_shape, \n","    num_labels, \n","    patch_size=16, \n","    patch_overlap=8, \n","    hidden_size=64, \n","    num_transformer_layers=12,\n","    num_heads=12,\n","    mlp_dim=256,\n","    dropout_rate=0.5, \n","    attention_dropout_rate=0.2,\n","    conv_dropout_rate=0.2\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5JkJiQYyvABr"},"outputs":[],"source":["LEARNING_RATE = 0.001\n","\n","# compile model\n","optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n","model.compile(\n","    optimizer=optimizer,\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy'],\n",")    "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1291,"status":"ok","timestamp":1681302253584,"user":{"displayName":"Sayantan Das","userId":"12952302728003162897"},"user_tz":-330},"id":"EHCzvnVZwcV3","outputId":"0fcd84cb-c9de-4234-e9b7-35170ceae3e7"},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AtiOHrstwc6R"},"outputs":[],"source":["if not os.path.isfile(os.path.join(model_save_loc, \"model_summary.txt\")):\n","    with open(os.path.join(model_save_loc, \"model_summary.txt\"), 'w') as f:\n","        with redirect_stdout(f):\n","            model.summary()\n","    print(\"Saved model summary ...\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N0MQUWCyv7rD"},"outputs":[],"source":["if not os.path.isfile(os.path.join(model_save_loc, \"model.json\")):\n","    model_json = model.to_json()\n","    with open(os.path.join(model_save_loc, \"model.json\"), \"w\") as json_file:\n","        json_file.write(model_json)\n","    print(\"Saved model json ...\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xdJ8MkY5wjPJ"},"source":["# **Train**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":751,"status":"ok","timestamp":1681302434232,"user":{"displayName":"Sayantan Das","userId":"12952302728003162897"},"user_tz":-330},"id":"FHxhXbJTwkoR","outputId":"d3e7c8d2-4066-4797-e682-d58812cf927d"},"outputs":[],"source":["prev_save_file = get_prev_save_file_name(model_save_loc)\n","prev_best_file = get_prev_best_save_file_name(model_save_loc)\n","prev_epoch = 0\n","prev_best_acc = 0\n","\n","if prev_save_file:\n","    print(\"Last best save file: \", prev_best_file)\n","    prev_best_acc = float(prev_best_file[-13:-8])\n","    print(\"Last best acc: \", prev_best_acc)\n","\n","    print(\"Last save file: \", prev_save_file)\n","    prev_epoch = int(prev_save_file[-12:-9])\n","    print(\"prev epoch:\", prev_epoch)\n","\n","    print(\"Loading weights...\")\n","    load_status = model.load_weights(os.path.join(model_save_loc,prev_save_file))\n","    # load_status.assert_consumed()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NYSRdaWQwozN"},"outputs":[],"source":["custom_checkpoint_callback = CustomModelCheckPoint(\n","                                    model_save_loc,\n","                                    prev_save_file=prev_save_file,\n","                                    prev_best_file=prev_best_file,\n","                                    prev_best_acc=prev_best_acc,\n","                                    model_name=\"vic\"\n","                                )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0g-X8XWkwqX1"},"outputs":[],"source":["csv_logger_callback = tf.keras.callbacks.CSVLogger(\n","        os.path.join(model_save_loc, \"logs.csv\"), separator=',', append=True\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e17ydmJWwtZt","outputId":"d24f3e85-b3ba-444c-ae33-4089b1579d78"},"outputs":[],"source":["num_epochs = 100\n","early_stopping_patience = 10\n","\n","\n","history = model.fit(\n","    train_ds,\n","    validation_data=val_ds,\n","    epochs=num_epochs, \n","    initial_epoch=prev_epoch,\n","    callbacks=[\n","        custom_checkpoint_callback,\n","        csv_logger_callback,\n","        tf.keras.callbacks.EarlyStopping( monitor='val_loss', patience=early_stopping_patience, verbose=1)\n","    ],\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"fdZb18Z4w9Bn"},"source":["# **Test**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41847,"status":"ok","timestamp":1681302409691,"user":{"displayName":"Sayantan Das","userId":"12952302728003162897"},"user_tz":-330},"id":"OqWq7ccUw8sm","outputId":"8a1f2547-1e41-4094-fac3-f75ae70fb997"},"outputs":[],"source":["results = model.evaluate(test_ds, verbose=1, return_dict=True)\n","print(results)"]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
